python -m llama_cpp.server ^
--model C:\Users\seyhan\Downloads\starcoder2-7b-Q4_0.gguf ^
--n_ctx 3000 