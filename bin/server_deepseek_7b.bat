python -m llama_cpp.server ^
--model C:\LLM\deepseek-coder-6.7b-instruct.Q4_0.gguf ^
--n_gpu_layers 10 ^
--n_ctx 8192 
